# üìä Performance Testing Methodology

## Objetivo

Medir latencia real end-to-end y tomar decisiones de optimizaci√≥n **√∫nicamente basadas en datos medidos**.

---

## üîß Checklist de Instrumentaci√≥n

### Frontend (widget-core.js) ‚úÖ

- [x] `FE_click_ts` - Click en "Try Look"
- [x] `FE_preupload_start_ts` - Inicio de pre-upload a CDN
- [x] `FE_preupload_end_ts` - Fin de pre-upload
- [x] `FE_request_sent_ts` - `fetch()` iniciado
- [x] `FE_response_received_ts` - Response recibido
- [x] `FE_render_start_ts` - Inicio de renderizado
- [x] `FE_render_done_ts` - Imagen visible en DOM
- [x] `FE_e2e_complete` - Resumen con todos los tiempos

### Backend (route.ts) ‚úÖ

- [x] `BE_request_received_ts` - Inicio del handler
- [x] `BE_body_parsed_ts` - Body JSON parseado
- [x] `BE_auth_done_ts` - API key validada
- [x] `BE_fal_request_sent_ts` - Llamada a FAL iniciada
- [x] `BE_fal_response_received_ts` - Respuesta de FAL recibida
- [x] `BE_response_sent_ts` - Response enviado
- [x] Cold start detection ‚úÖ

### Correlaci√≥n ‚úÖ

- [x] `request_id` generado en frontend
- [x] Propagado a backend via `_requestId`
- [x] Timings devueltos en response `metadata.timings`

---

## üìù Formato de Logs

### Estructura JSON

```json
{
  "level": "info",
  "type": "timing",
  "request_id": "1736512800000-k3m9x2",
  "source": "frontend|backend",
  "phase": "string",
  "timestamp_iso": "2026-01-10T15:30:00.123Z",
  "timestamp_ms": 1736512800123,
  "duration_ms": 150,
  "metadata": { ... }
}
```

### D√≥nde Ver Logs

| Capa | D√≥nde |
|------|-------|
| Frontend | DevTools ‚Üí Console (buscar `[TryOn Timing]`) |
| Backend | Vercel Dashboard ‚Üí Functions ‚Üí Logs |

---

## üß™ Metodolog√≠a de Prueba

### Cantidad de Ejecuciones

| Tipo | M√≠nimo | Recomendado |
|------|--------|-------------|
| Total | 20 | 50 |
| Cold Start | 5 | 10 |
| Warm | 15 | 40 |

### C√≥mo Forzar Cold Start

```bash
# Esperar 5+ minutos entre requests
# O re-deployar la funci√≥n
```

### C√≥mo Forzar Warm

```bash
# Ejecutar en r√°fagas de 3-5 requests
# Con <30 segundos entre cada una
```

### Script de Prueba Recomendado

```bash
# 1. Cold start (esperar 5 min antes)
curl -X POST https://tu-dominio.vercel.app/api/images/generate \
  -H "Content-Type: application/json" \
  -d '{"apiKey":"xxx", "userImage":"...", "garments":["..."]}'

# 2. Warm requests (inmediatamente despu√©s)
for i in {1..5}; do
  curl -X POST https://tu-dominio.vercel.app/api/images/generate \
    -H "Content-Type: application/json" \
    -d '{"apiKey":"xxx", "userImage":"...", "garments":["..."]}' &
  sleep 2
done
wait
```

---

## üìä C√≥mo Analizar Resultados

### 1. Recolectar Logs

```bash
# Frontend: Copiar logs del DevTools
# Backend: Exportar desde Vercel

# Combinar en un archivo
cat frontend-logs.txt backend-logs.txt > all-logs.json
```

### 2. Ejecutar An√°lisis

```bash
npx ts-node scripts/analyze-latency.ts < all-logs.json
```

### 3. Interpretar Output

El script genera:

1. **Tabla de latencias por tramo** (avg, min, max, p50, p95, stddev)
2. **Cold vs Warm comparison**
3. **Bottleneck analysis** (qu√© segmento domina)
4. **Recommended actions** (qu√© optimizar)

---

## üéØ Tabla de Tiempos por Tramo (Target vs Alerta)

| Tramo | Target | Alerta |
|-------|--------|--------|
| FE Pre-upload | <200ms | >500ms |
| Network Up | <150ms | >500ms |
| BE Overhead | <100ms | >300ms |
| FAL Inference | <4000ms | >6000ms |
| Network Down | <150ms | >500ms |
| FE Render | <100ms | >300ms |
| **TOTAL E2E** | **<5000ms** | **>8000ms** |

---

## üîç Reglas de Decisi√≥n

### IF fal_inference > 4000ms AND stddev > 1000ms
‚Üí **Problema:** FAL cold starts
‚Üí **Acci√≥n:** Implementar warmup de FAL

### IF fal_inference > 4000ms AND stddev < 500ms
‚Üí **Problema:** Velocidad del modelo
‚Üí **Acci√≥n:** No se puede optimizar (es el tiempo de inferencia puro)

### IF cold_avg - warm_avg > 500ms
‚Üí **Problema:** Serverless cold starts
‚Üí **Acci√≥n:** Implementar cron warmup

### IF network > 300ms
‚Üí **Problema:** Payload grande o latencia de red
‚Üí **Acci√≥n:** Verificar CDN, comprimir m√°s, usar regiones cercanas

### IF be_overhead > 100ms
‚Üí **Problema:** C√≥digo lento en backend
‚Üí **Acci√≥n:** Optimizar auth, parsing, etc.

---

## ‚úÖ Validaci√≥n de Optimizaciones

### Proceso

1. **ANTES:** Correr 20+ requests, calcular avg y p95
2. **APLICAR** la optimizaci√≥n
3. **DESPU√âS:** Correr 20+ requests, calcular avg y p95
4. **COMPARAR:**

```
IF avg_despu√©s < avg_antes * 0.9:
    √âXITO (>10% mejora)
ELSE:
    SIN IMPACTO ‚Üí REVERTIR
```

### Registro

```markdown
| Optimizaci√≥n | Antes (avg) | Despu√©s (avg) | Œî | Resultado |
|--------------|-------------|---------------|---|-----------|
| Pre-upload CDN | 6500ms | 5200ms | -20% | ‚úÖ APLICAR |
| Warmup cron | 5200ms | 5100ms | -2% | ‚ùå REVERTIR |
```

---

## üö® Troubleshooting

### No veo logs de Frontend
- Verificar que el widget carga correctamente
- Buscar `[TryOn Timing]` en DevTools Console
- Los logs solo aparecen despu√©s de hacer click en "Try Look"

### No veo logs de Backend
- Verificar que Vercel Function Logs est√°n habilitados
- Buscar `"type":"timing"` o `"type":"latency"`
- Los logs tardan ~30s en aparecer en Vercel Dashboard

### request_id no coincide
- Verificar que el widget env√≠a `_requestId` en el payload
- Verificar que route.ts lee `body._requestId`

### Cold start siempre true
- Normal en desarrollo/staging
- En producci√≥n, despu√©s de 3+ requests seguidas deber√≠a ser `false`
